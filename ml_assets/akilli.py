# -*- coding: utf-8 -*-
"""AKILLI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ICiB1xTXQTiTLr7YKPcUpk7wZ5hygL8h
"""

# pip install pandas numpy scikit-learn joblib

# Gerekli kütüphaneleri içe aktarma
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
import joblib # Modeli ve ölçekleyiciyi kaydetmek için

import pandas as pd

data = pd.read_csv('yeni_birleşmiş.csv', encoding='latin1')
data.head()

# İlk 5 satırı gör
data.head()

# Sütun adlarını listele
print(data.columns)

# Veri tipi ve eksik değer durumunu incele
data.info()

# Sayısal sütunların temel istatistikleri
data.describe()

# Hangi sütunda kaç eksik değer var
data.isnull().sum()

# Eksik verileri sil
data = data.dropna()

# veya doldur
data = data.fillna(0)  # ya da ortalama ile doldurabilirsin

import pandas as pd
import numpy as np

# --- 1. Veri Setini Yükleme ve DataFrame'i Tanımlama (df) ---
# df'nin tanımlı olmaması NameError'a yol açar. Bu adım zorunludur.
try:
    df = pd.read_csv('yeni_birleşmiş.csv', encoding='utf-8')
except:
    # Kullanıcının dosyasının kodlaması farklıysa diye latin-1 deneme
    df = pd.read_csv('yeni_birleşmiş.csv', encoding='latin-1')

print("Veri Seti Başarıyla Yüklendi ve 'df' değişkenine atandı.")

# --- 2. Sütun Temizliği ---
# Önceden tespit edilen sorunlu/tekrarlanan sütunları düşürme
columns_to_drop = ['bmi.1', 'blood_glucose_level.1', 'diabetes.1']
df = df.drop(columns=columns_to_drop, errors='ignore')

# --- 3. Veri Tipi Düzeltme ---
# 'age' ve 'bmi' sütunlarını sayısal türe dönüştürme
# Hatalı değerler (örneğin '18.Ağu') bu adımda NaN'a döner
df['age'] = pd.to_numeric(df['age'], errors='coerce')
df['bmi'] = pd.to_numeric(df['bmi'], errors='coerce')

# --- 4. Eksik Veri Doldurma ---
# Eksik değerleri medyan ile doldurma (NameError vermeyen kısım)
df['age'] = df['age'].fillna(df['age'].median())
df['bmi'] = df['bmi'].fillna(df['bmi'].median())

# Kalan tüm eksik değerleri içeren satırları düşürme (kategorik sütunlar için)
df = df.dropna()

print(f"\nTemizlenmiş veri seti boyutu: {df.shape}")
print("\nEksik Değer Kontrolü:")
print(df.isnull().sum())

# ==============================================================================
# TÜM MODELLER VE ANALİZLER İÇİN EKSİKSİZ, TEK KOD BLOĞU
# ==============================================================================

# ==============================================================================
# BÖLÜM 0: KURULUM VE KÜTÜPHANELER
# ==============================================================================

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
import joblib

# ==============================================================================
# BÖLÜM 1: VERİ YÜKLEME VE TEMİZLİK (TÜM MODELLER İÇİN TEK SEFERDE)
# ==============================================================================

# --- Veri Setini Yükleme ---
try:
    df = pd.read_csv('yeni_birleşmiş.csv', encoding='utf-8')
except:
    df = pd.read_csv('yeni_birleşmiş.csv', encoding='latin-1')

print("Veri Seti Başarıyla Yüklendi.")

# --- Temel Veri Temizliği ---
# Tüm modellerde hedef olmayan, yinelenen ve sorunlu sütunları düşürme
columns_to_drop_initial = ['bmi.1', 'blood_glucose_level.1', 'diabetes.1', 'Food_Item', 'heart_disease', 'cardio', 'hypertension']
df = df.drop(columns=columns_to_drop_initial, errors='ignore')

# Sayısal Türe Dönüştürme ve Eksik Değer Doldurma (Medyan ile)
df['bmi'] = pd.to_numeric(df['bmi'], errors='coerce')
df['age'] = pd.to_numeric(df['age'], errors='coerce')
df['age'] = df['age'].fillna(df['age'].median())
df['bmi'] = df['bmi'].fillna(df['bmi'].median())
df = df.dropna()

# --- Kategorik Kodlama (One-Hot Encoding) ---
categorical_cols = df.select_dtypes(include=['object']).columns
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# Sütun adlarını temizleme
df_encoded.columns = df_encoded.columns.str.replace(r'[^A-Za-z0-9_]+', '', regex=True)
df_encoded.columns = df_encoded.columns.str.replace(' ', '_', regex=True)
df_encoded.columns = df_encoded.columns.str.replace(r'[ıöüçşğ]', '', regex=True)

# --- Ölçekleme İçin Orijinal Sürekli Sütunlar Listesi ---
COLS_TO_SCALE_ORIGINAL = ['age', 'bmi', 'blood_glucose_level', 'Calories_kcal', 'Sodium_mg', 'Cholesterol_mg', 'Water_Intake_ml', 'active', 'diabetes']

# ==============================================================================
# BÖLÜM 2: TÜM HEDEF DEĞİŞKENLERİNİN TANIMLANMASI
# ==============================================================================

# Model 2: Yüksek Kan Şekeri Riski
df_encoded['High_Sugar_Risk'] = np.where(df_encoded['blood_glucose_level'] >= 140, 1, 0)
# Model 3: Obezite Riski
df_encoded['Obesity_Risk'] = np.where(df_encoded['bmi'] >= 30.0, 1, 0)
# Model 4: Yüksek Kanser Risk Faktörü
is_smoker = (df_encoded['smoking_history_current'] == 1) | (df_encoded['smoking_history_former'] == 1)
is_obese = df_encoded['bmi'] >= 30
df_encoded['Cancer_Risk_Score'] = np.where(is_smoker & is_obese, 1, 0)
# Model 5: Düşük Fiziksel Aktivite
df_encoded['Low_Activity_Score'] = np.where(df_encoded['active'] == 0, 1, 0)
# Model 6: Yüksek Kolesterol
cholesterol_median = df_encoded['Cholesterolmg'].median()
cholesterol_threshold = cholesterol_median * 1.15
df_encoded['High_Cholesterol_Risk'] = np.where(df_encoded['Cholesterolmg'] > cholesterol_threshold, 1, 0)


# ==============================================================================
# BÖLÜM 3: MODEL EĞİTİMİ VE KAYIT FONKSİYONU
# ==============================================================================

def run_model_and_save(df_base, target_col, dropped_features, model_id, model_name_tag, comparison_mode=False):
    """Belirtilen hedef üzerinde modelleri eğitir, sonuçları hesaplar ve kaydeder."""

    df_model = df_base.copy()

    y = df_model[target_col]
    X = df_model.drop(target_col, axis=1)

    # Target Leakage'ı Önlemek için Türetilen Özellikleri Çıkarma
    for col in dropped_features:
        if col in X.columns:
            X = X.drop(col, axis=1)

    # Veri Ayırma
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # Ölçekleme
    cols_to_scale = [col for col in COLS_TO_SCALE_ORIGINAL if col in X_train.columns]
    scaler = StandardScaler()
    X_train_scaled = X_train.copy()
    X_test_scaled = X_test.copy()
    X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])
    X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])

    # Model Eğitimi ve Değerlendirme
    models = {
        'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced'),
        'Lojistik Regresyon': LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced'),
        'K-En Yakın Komşu': KNeighborsClassifier(n_neighbors=5)
    }

    accuracy_results = {}

    for model_name, model in models.items():
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        accuracy_results[model_name] = accuracy

        # Sadece Random Forest modelini kaydediyoruz ve raporunu yazdırıyoruz
        if model_name == 'Random Forest' and not comparison_mode:
            print(f"\n--- {model_id} ({model_name_tag}): Random Forest Performans Raporu ---")
            print(f"Doğruluk: {accuracy:.4f}")
            print(classification_report(y_test, y_pred))

            # Özellik Önem Derecelerini CSV olarak kaydetme
            feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)
            feature_importances = feature_importances.sort_values(ascending=False)
            feature_importances_df = pd.DataFrame(feature_importances)
            feature_importances_df.columns = ['Importance']
            feature_importances_df.to_csv(f'{model_name_tag}_feature_importances.csv')
            print(f"✅ Önemli Özellikler CSV olarak kaydedildi: {model_name_tag}_feature_importances.csv")

            # Modeli ve Ölçekleyiciyi kaydetme
            joblib.dump(model, f'{model_name_tag}_model.joblib')
            joblib.dump(scaler, f'scaler_for_{model_name_tag}_model.joblib')
            print(f"✅ {model_id} kaydedildi: {model_name_tag}_model.joblib")

    return accuracy_results


# ==============================================================================
# BÖLÜM 4: MODELLERİN ÇALIŞTIRILMASI VE SONUÇLARIN TOPLANMASI
# ==============================================================================

all_comparison_results = []
models_list = [
    ('Model 1', 'diabetes_risk', 'diabetes', []),
    ('Model 2', 'high_sugar_risk', 'High_Sugar_Risk', ['blood_glucose_level', 'diabetes']),
    ('Model 3', 'obesity_risk', 'Obesity_Risk', ['bmi']),
    ('Model 4', 'cancer_risk', 'Cancer_Risk_Score', []),
    ('Model 5', 'low_activity_risk', 'Low_Activity_Score', ['active']),
    ('Model 6', 'high_cholesterol_risk', 'High_Cholesterol_Risk', ['Cholesterolmg'])
]

print(f"\nBaşlatılıyor: Toplam {len(models_list)} Model Eğitilecek.")

for model_id, model_name_tag, target_col, dropped_features in models_list:
    # 1. Random Forest Modelini Eğitme ve Detaylı Raporları/Dosyaları Kaydetme
    run_model_and_save(df_encoded, target_col, dropped_features, model_id, model_name_tag, comparison_mode=False)

    # 2. Kıyaslama Skorlarını Alma
    scores = run_model_and_save(df_encoded, target_col, dropped_features, model_id, model_name_tag, comparison_mode=True)

    # Sonuçları ana listeye ekleme
    for algo, acc in scores.items():
        all_comparison_results.append({
            'Model ID': model_id,
            'Hedef Değişken': target_col,
            'Algoritma': algo,
            'Doğruluk Oranı': acc
        })


# ==============================================================================
# BÖLÜM 5: NİHAİ KIYASLAMA TABLOSU OLUŞTURMA VE KAYDETME
# ==============================================================================

df_final_comparison = pd.DataFrame(all_comparison_results)

# Doğruluk Oranını Yüzde olarak biçimlendirme
df_final_comparison['Doğruluk Oranı (%)'] = (df_final_comparison['Doğruluk Oranı'] * 100).round(2)

# Pivot tablo oluşturma
df_pivot = df_final_comparison.pivot_table(
    index=['Model ID', 'Hedef Değişken'],
    columns='Algoritma',
    values='Doğruluk Oranı (%)'
)

# Nihai CSV olarak kaydetme (Raporunuzun Kanıtı)
df_pivot.to_csv('all_models_comparison_table.csv')

print("\n--- NİHAİ ÇIKTI ÖZETİ ---")
print("✅ Tüm Modellerin Detaylı Raporları ve 18 adet Joblib/CSV Dosyası Oluşturuldu.")
print("✅ Kanıtınız olan Kıyaslama Tablosu CSV olarak kaydedildi: all_models_comparison_table.csv")